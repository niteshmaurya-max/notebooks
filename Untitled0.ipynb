{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niteshmaurya-max/notebooks/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_9MJZhfRBPR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0678199"
      },
      "source": [
        "# Task\n",
        "Create a Python program for Raspberry Pi 5 that uses the Gemini API to answer children's questions in simple language, taking voice input and providing voice output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a6e8960"
      },
      "source": [
        "## Set up the raspberry pi environment\n",
        "\n",
        "### Subtask:\n",
        "Install necessary libraries for audio processing and the Gemini API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01bf4ca8"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to update the system packages on the Raspberry Pi. This will ensure we have the latest versions of the software before installing new libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca8e1583"
      },
      "source": [
        "# This command needs to be executed on the Raspberry Pi terminal\n",
        "# !sudo apt update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b10e382a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the package list is updated, I need to upgrade the installed packages and then install the required libraries for audio processing (`portaudio19-dev`, `python3-pyaudio`) and the Gemini API (`google-generativeai`), speech-to-text (`SpeechRecognition`, `pyaudio`), and text-to-speech (`gTTS`). I can group these installation steps into a single code block for efficiency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "995116db"
      },
      "source": [
        "# These commands need to be executed on the Raspberry Pi terminal\n",
        "# !sudo apt upgrade -y\n",
        "# !sudo apt install portaudio19-dev python3-pyaudio -y\n",
        "# !pip install google-generativeai SpeechRecognition pyaudio gTTS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba4c4cf"
      },
      "source": [
        "## Implement speech-to-text\n",
        "\n",
        "### Subtask:\n",
        "Use a library to convert the child's voice input into text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12e47b62"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the `speech_recognition` library and instantiate a `Recognizer` object. This addresses steps 1 and 2 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d76d5f6a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to import `speech_recognition` failed because the library is not installed in this environment. Although the initial plan was to install libraries on the Raspberry Pi, the current execution environment is not that device. Since the subtask is to demonstrate the code for voice-to-text conversion, I need to install the required library in this environment to proceed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb9a8c93"
      },
      "source": [
        "## Implement speech-to-text\n",
        "\n",
        "### Subtask:\n",
        "Retry implementing speech-to-text. Use a library to convert the child's voice input into text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92330b07"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the speech-to-text functionality using the `speech_recognition` and `pyaudio` libraries, handling potential errors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "404e3a87"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to import `speech_recognition` failed because the module was not found. Need to install the required libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0cd41dc"
      },
      "source": [
        "## Process the text input\n",
        "\n",
        "### Subtask:\n",
        "Use the Gemini API to understand the child's query and generate a simple, child-friendly response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "075d5235"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the google.generativeai library, configure it with a placeholder API key, initialize the generative model, define a function to process child's queries, create a suitable prompt within the function, generate a response using the model, extract the text, and return the response.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6df1c0b"
      },
      "source": [
        "## Implement text-to-speech\n",
        "\n",
        "### Subtask:\n",
        "Use a library to convert the Gemini API's text response into speech.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10ff7dac"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the gTTS library and define a function to convert text to speech.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fcd153b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `gtts` library was not found. Install the library using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4791c95a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `gTTS` library is installed, try importing it and defining the text-to-speech function again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df4a0eaa"
      },
      "source": [
        "## Integrate the components\n",
        "\n",
        "### Subtask:\n",
        "Combine the Speech-to-Text, Gemini API processing, and Text-to-Speech components to create a conversational flow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86208521"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries and functions from the previously completed subtasks: Speech-to-Text, Gemini API processing, and Text-to-Speech.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c355e5a7"
      },
      "source": [
        "**Reasoning**:\n",
        "The `speech_recognition` library is not installed. Install the missing library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1e139cb"
      },
      "source": [
        "## Integrate the components\n",
        "\n",
        "### Subtask:\n",
        "Retry integrating the components. Combine the Speech-to-Text, Gemini API processing, and Text-to-Speech components to create a conversational flow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1929a24"
      },
      "source": [
        "**Reasoning**:\n",
        "Attempt to install the `speech_recognition` library again, as it was not successfully installed in the previous attempt and is required for speech-to-text functionality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c874e550"
      },
      "source": [
        "## Integrate the components\n",
        "\n",
        "### Subtask:\n",
        "Retry integrating the components. Combine the Speech-to-Text, Gemini API processing, and Text-to-Speech components to create a conversational flow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edd7405"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries and define the `listen_and_respond` function to integrate the components for the conversational flow. Include error handling and the loop mechanism as requested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75365b6b"
      },
      "source": [
        "## Integrate the components\n",
        "\n",
        "### Subtask:\n",
        "Retry integrating the components. Combine the Speech-to-Text, Gemini API processing, and Text-to-Speech components to create a conversational flow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2d40013"
      },
      "source": [
        "**Reasoning**:\n",
        "Acknowledge the installation issue and present the integrated code with comments and instructions as requested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "054f1a84"
      },
      "source": [
        "## Test and refine\n",
        "\n",
        "### Subtask:\n",
        "Test the program with sample inputs and refine the responses and voice interactions for a child audience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0b3317d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The primary obstacle throughout the process was the inability to install the `speech_recognition` library and its dependencies (`pyaudio`) within the execution environment, which prevented the implementation and testing of the speech-to-text and integrated conversational flow components.\n",
        "*   The code for processing text input using the Gemini API (`get_child_friendly_answer` function) was successfully developed, including setting up the model and crafting a child-friendly prompt structure.\n",
        "*   The code for text-to-speech conversion using `gTTS` (`text_to_speech` function) was also successfully developed and demonstrated, although the actual audio playback on a Raspberry Pi would require additional steps.\n",
        "*   Integrated Python code combining the three components was generated, but its execution failed due to the missing `speech_recognition` dependency.\n",
        "*   Instructions and recommended installation commands for setting up the necessary libraries on the target Raspberry Pi environment were provided to the user.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The user needs to execute the provided installation commands directly on their Raspberry Pi to install `speech_recognition`, `pyaudio`, and other required libraries before the integrated code can function correctly.\n",
        "*   Once the libraries are installed on the Raspberry Pi, the user can execute the integrated Python script and proceed with testing and refining the program's performance with actual voice inputs and outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e576813"
      },
      "source": [
        "# This code is intended to be run on a Raspberry Pi 5.\n",
        "# Ensure you have the necessary libraries installed by running the following commands on your Raspberry Pi terminal:\n",
        "# sudo apt update && sudo apt upgrade -y\n",
        "# sudo apt install portaudio19-dev python3-pyaudio -y\n",
        "# pip install google-generativeai SpeechRecognition pyaudio gTTS\n",
        "\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import google.generativeai as gen\n",
        "\n",
        "# Global variable to store conversation history\n",
        "conversation_history = []\n",
        "\n",
        "def get_child_friendly_answer(question):\n",
        "  \"\"\"\n",
        "  Uses the Gemini API to answer a child's question in simple language,\n",
        "  remembering previous turns in the conversation.\n",
        "\n",
        "  Args:\n",
        "    question: The child's question as a string.\n",
        "\n",
        "  Returns:\n",
        "    A string containing the child-friendly answer.\n",
        "  \"\"\"\n",
        "  # Configure the Gemini API with your API key\n",
        "  # Replace 'YOUR_API_KEY' with your actual API key\n",
        "  # It is recommended to store your API key securely, e.g., using environment variables.\n",
        "  gen.configure(api_key='YOUR_API_KEY')\n",
        "\n",
        "  # Initialize the generative model\n",
        "  # You can choose a different model if needed.\n",
        "  model = gen.GenerativeModel('gemini-pro')\n",
        "\n",
        "  # Add the current question to the conversation history\n",
        "  conversation_history.append(f\"Child: {question}\")\n",
        "\n",
        "  # Create a prompt for the model including the conversation history\n",
        "  prompt = \"Here is our conversation so far:\\n\" + \"\\n\".join(conversation_history) + \\\n",
        "           \"\\n\\nAnswer the child's question in simple language. After answering, ask if they want to start a new session to clear the history.\"\n",
        "\n",
        "  # Generate a response from the model\n",
        "  try:\n",
        "    response = model.generate_content(prompt)\n",
        "    # Extract the text content from the response\n",
        "    answer = response.text\n",
        "    # Add the AI's response to the conversation history\n",
        "    conversation_history.append(f\"AI: {answer}\")\n",
        "    return answer\n",
        "  except Exception as e:\n",
        "    print(f\"Error generating response from Gemini API: {e}\")\n",
        "    return \"Sorry, I couldn't get an answer for you right now.\"\n",
        "\n",
        "\n",
        "def text_to_speech(text, output_file=\"output.mp3\"):\n",
        "  \"\"\"\n",
        "  Converts text to speech using gTTS and saves it to an audio file.\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "    output_file: The name of the output audio file (default: \"output.mp3\").\n",
        "  \"\"\"\n",
        "  try:\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    tts.save(output_file)\n",
        "    print(f\"Speech saved to {output_file}\")\n",
        "    # On Raspberry Pi, you would typically play this file using a command like:\n",
        "    # os.system(\"mpg321 \" + output_file)\n",
        "    # You might need to install mpg321: sudo apt-get install mpg321\n",
        "  except Exception as e:\n",
        "    print(f\"Error during text-to-speech conversion: {e}\")\n",
        "\n",
        "def listen_and_respond():\n",
        "  \"\"\"\n",
        "  Orchestrates the conversational flow: listen, process, and respond.\n",
        "  Includes option to clear history.\n",
        "  \"\"\"\n",
        "  global conversation_history # Declare that we are using the global variable\n",
        "  r = sr.Recognizer()\n",
        "  with sr.Microphone() as source:\n",
        "    print(\"Adjusting for ambient noise, please wait...\")\n",
        "    r.adjust_for_ambient_noise(source, duration=5) # Adjust for 5 seconds of ambient noise\n",
        "    print(\"Say something!\")\n",
        "\n",
        "    while True:\n",
        "      try:\n",
        "        print(\"Listening...\")\n",
        "        audio = r.listen(source, timeout=10, phrase_time_limit=10) # Listen for up to 10 seconds\n",
        "        print(\"Processing...\")\n",
        "        text = r.recognize_google(audio)\n",
        "        print(f\"You said: {text}\")\n",
        "\n",
        "        if text.lower() == \"goodbye\":\n",
        "          print(\"Goodbye!\")\n",
        "          text_to_speech(\"Goodbye!\")\n",
        "          break\n",
        "        elif \"start a new session\" in text.lower() or \"clear the history\" in text.lower():\n",
        "            print(\"Starting a new session...\")\n",
        "            conversation_history = [] # Clear the history\n",
        "            text_to_speech(\"Okay, let's start a new session. What would you like to talk about?\")\n",
        "            continue # Skip to the next iteration of the loop\n",
        "\n",
        "        answer = get_child_friendly_answer(text)\n",
        "        print(\"Here is the answer...\")\n",
        "        print(answer)\n",
        "        text_to_speech(answer)\n",
        "\n",
        "      except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio\")\n",
        "        text_to_speech(\"Sorry, I didn't understand that.\")\n",
        "      except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "        text_to_speech(\"Sorry, there was an error with the speech recognition service.\")\n",
        "      except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        text_to_speech(\"Sorry, an error occurred.\")\n",
        "\n",
        "# To start the interaction on your Raspberry Pi, uncomment the line below and run the script:\n",
        "# listen_and_respond()\n",
        "\n",
        "# Example of how to get an answer without voice input (for testing the Gemini API part):\n",
        "# test_question = \"What do bees eat?\"\n",
        "# test_answer = get_child_friendly_answer(test_question)\n",
        "# print(f\"\\nTest question: {test_question}\")\n",
        "# print(f\"Test answer: {test_answer}\")\n",
        "# text_to_speech(test_answer, output_file=\"test_answer.mp3\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}